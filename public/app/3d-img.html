<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1" />
  <title>Photo/Video to 3D Space — Projection Reconstructor</title>
  <style>
    :root {
      --bg: #0b0f14;
      --panel: #121821;
      --panel2: #0e141c;
      --accent: #4cc9f0;
      --accent2: #72efdd;
      --text: #e9edf3;
      --muted: #8fa1b8;
      --danger: #ff6b6b;
      --ok: #80ffdb;
    }
    * { box-sizing: border-box }
    html,body { height: 100%; margin: 0; background: radial-gradient(1200px at 20% 10%, #0f1622 0%, #0b0f14 60%); color: var(--text); font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, "Helvetica Neue", Arial, "Noto Sans", "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol"; }
    #app { display: grid; grid-template-columns: 380px 1fr; gap: 0; height: 100%; }
    aside {
      background: linear-gradient(180deg, var(--panel) 0%, var(--panel2) 100%);
      border-right: 1px solid #1b2430;
      padding: 18px 18px 12px;
      overflow: auto;
    }
    header { display: flex; align-items: center; gap: 12px; margin-bottom: 12px; }
    .logo {
      width: 40px; height: 40px; border-radius: 12px;
      background: conic-gradient(from 190deg, #2f80ed, #56ccf2, #80ffdb, #2f80ed);
      box-shadow: 0 0 24px rgba(76,201,240,0.25), inset 0 0 24px rgba(128,255,219,0.2);
    }
    h1 { font-size: 18px; margin: 0; letter-spacing: 0.2px }
    .sub { color: var(--muted); font-size: 12px }
    .card {
      background: #0f141c; border: 1px solid #1b2430; border-radius: 14px;
      padding: 14px; margin: 10px 0; box-shadow: 0 10px 30px rgba(0,0,0,0.25);
    }
    .card h2 { font-size: 14px; letter-spacing: .2px; margin: 0 0 10px; color: #bcd2f0 }
    .drop {
      border: 1px dashed #2b3a4f; border-radius: 14px; padding: 16px;
      display: grid; place-items: center; text-align: center; color: var(--muted);
      transition: border-color .2s, background .2s;
    }
    .drop.drag { border-color: var(--accent); background: #101827; color: #cfeaff }
    input[type="file"] { display: none }
    .btn {
      display: inline-flex; align-items: center; gap: 8px; padding: 10px 14px;
      border-radius: 10px; border: 1px solid #234; color: #dff6ff; background: #0e1a25;
      cursor: pointer; transition: transform .05s ease, box-shadow .2s ease, background .2s ease;
    }
    .btn:hover { background: #0b1620; box-shadow: 0 10px 24px rgba(76,201,240,0.1) }
    .btn:active { transform: translateY(1px) }
    .accent { border-color: #255; background: linear-gradient(180deg, #0e1f2c 0%, #0a1723 100%); }
    .accent .dot {
      width: 8px; height: 8px; border-radius: 50%; background: var(--accent);
      box-shadow: 0 0 16px var(--accent);
    }
    .row { display: flex; gap: 10px; align-items: center; flex-wrap: wrap }
    .hint { font-size: 12px; color: var(--muted) }
    .kv { display: grid; grid-template-columns: 1fr 1fr; gap: 8px; }
    .kv .item { background: #0c131b; border: 1px solid #1b2430; border-radius: 10px; padding: 8px 10px; }
    .kv .label { font-size: 11px; color: var(--muted) }
    .kv .value { font-size: 13px; color: #d6e8ff }
    .progress { height: 8px; border-radius: 8px; background: #0d1722; border: 1px solid #1c2836; overflow: hidden; }
    .bar { height: 100%; width: 0; background: linear-gradient(90deg, var(--accent), var(--accent2)); transition: width .2s }
    .status { font-size: 12px; color: #bcd2f0; margin-top: 6px }
    .warn { color: #ffd166 }
    .ok { color: var(--ok) }
    .err { color: var(--danger) }
    .toggle { display: flex; gap: 8px; align-items: center; }
    .toggle input { accent-color: var(--accent) }
    .slider { width: 100%; }
    .footnote { color: var(--muted); font-size: 11px; margin-top: 10px }
    .pill {
      display: inline-block; font-size: 11px; color: #9fd9ff; border: 1px solid #1e2b3b;
      background: #0c151f; padding: 4px 8px; border-radius: 999px; margin-right: 6px;
    }

    /* 3D viewport */
    main { position: relative; }
    #viewport { width: 100%; height: 100%; display: block; }
    .hud {
      position: absolute; left: 16px; bottom: 16px;
      display: flex; gap: 8px; flex-wrap: wrap;
    }
    .hud .key {
      border: 1px solid #223; border-radius: 8px; padding: 6px 8px; font-size: 12px; color: #cfeaff;
      background: rgba(14, 26, 37, 0.75); backdrop-filter: blur(6px);
    }
    .centerTip {
      position: absolute; left: 50%; top: 50%; transform: translate(-50%, -50%);
      color: #cfeaff; font-size: 14px; padding: 8px 12px; border: 1px solid #234;
      background: rgba(10,16,24,.65); border-radius: 12px; opacity: 0; transition: opacity .2s;
    }
    .centerTip.show { opacity: 1 }
    .tag {
      position: absolute; right: 16px; top: 16px; font-size: 12px; color: #9fd9ff;
      padding: 6px 10px; border: 1px solid #223; background: rgba(14,26,37,.6); border-radius: 999px;
    }
    canvas:focus { outline: none }
    .help {
      font-size: 12px; color: #9fb6d4; margin-top: 6px;
    }
    .divider { height: 1px; background: #1b2430; margin: 12px 0; opacity: .7 }
  </style>
</head>
<body>
  <div id="app">
    <aside>
      <header>
        <div class="logo"></div>
        <div>
          <h1>Projection Reconstructor</h1>
          <div class="sub">写真・動画からリアルな3D空間へ（AI不使用）</div>
        </div>
      </header>

      <div class="card">
        <h2>ファイルを選択</h2>
        <div id="drop" class="drop">
          <div>
            <div style="font-size:13px; color:#cfeaff">画像または動画をドラッグ＆ドロップ</div>
            <div class="hint">対応: JPG/PNG/WebP, MP4/WebM（先頭フレームを利用）</div>
            <div class="row" style="margin-top:10px">
              <label class="btn accent" for="file">
                <span class="dot"></span> ファイルを選ぶ
              </label>
              <button id="demoBtn" class="btn">デモ画像</button>
            </div>
          </div>
        </div>
        <input id="file" type="file" accept="image/*,video/*" />
        <div class="kv" style="margin-top:10px">
          <div class="item"><div class="label">種類</div><div id="kind" class="value">—</div></div>
          <div class="item"><div class="label">解像度</div><div id="res" class="value">—</div></div>
          <div class="item"><div class="label">推定消失点</div><div id="vp" class="value">—</div></div>
          <div class="item"><div class="label">射影誤差</div><div id="err" class="value">—</div></div>
        </div>
        <div class="progress" style="margin-top:10px"><div id="bar" class="bar"></div></div>
        <div id="status" class="status">準備完了</div>
        <div class="footnote">
          <span class="pill">AI不使用</span>
          <span class="pill">クラシカルCV</span>
          <span class="pill">WebGL/Three.js</span>
        </div>
      </div>

      <div class="card">
        <h2>再構築設定（自動）</h2>
        <div class="toggle">
          <input id="autoVP" type="checkbox" checked />
          <label for="autoVP">消失点を自動推定</label>
        </div>
        <div class="toggle" style="margin-top:6px">
          <input id="depthFromLuma" type="checkbox" checked />
          <label for="depthFromLuma">輝度ベースの奥行き補正</label>
        </div>
        <div style="margin-top:8px">
          <div class="label">スケール（奥行き感）</div>
          <input id="depthScale" class="slider" type="range" min="0" max="1.5" step="0.01" value="0.6" />
        </div>
        <div style="margin-top:8px">
          <div class="label">露出補正</div>
          <input id="exposure" class="slider" type="range" min="0.25" max="2.0" step="0.01" value="1.0" />
        </div>
        <div style="margin-top:8px">
          <div class="label">FOV（投影カメラ）</div>
          <input id="projFov" class="slider" type="range" min="30" max="90" step="1" value="60" />
        </div>
        <div class="help">設定はアップロード時に自動反映。変更後は「更新」を押すと再投影。</div>
        <div class="row" style="margin-top:8px">
          <button id="reproject" class="btn">更新</button>
          <button id="resetScene" class="btn">シーン初期化</button>
        </div>
        <div class="divider"></div>
        <div class="help">精度重視のため、画像はできるだけ平面の壁・床が写っているものがおすすめ。</div>
      </div>

      <div class="card">
        <h2>操作</h2>
        <div class="help">キャンバスをクリックしてポインタロック。WASD移動、マウスで視点回転、Shiftで走る。</div>
        <div class="kv">
          <div class="item"><div class="label">速度</div><div id="speedVal" class="value">2.5 m/s</div></div>
          <div class="item"><div class="label">回転感度</div><div id="sensVal" class="value">0.002</div></div>
        </div>
        <div style="margin-top:8px">
          <div class="label">速度</div>
          <input id="speed" class="slider" type="range" min="0.5" max="8" step="0.1" value="2.5" />
        </div>
        <div style="margin-top:8px">
          <div class="label">回転感度</div>
          <input id="sens" class="slider" type="range" min="0.001" max="0.01" step="0.0005" value="0.002" />
        </div>
      </div>

      <div class="card">
        <h2>注意</h2>
        <div class="help">
          ブラウザのみ（AI不使用）で、消失点推定と射影再構築を行います。動画は先頭フレームを投影に使います。複雑な3Dメッシュの自動生成（フォトグラメトリ完全同等）は対象外ですが、奥行きを感じるリアルな空間を体験できます。
        </div>
      </div>
    </aside>

    <main>
      <canvas id="viewport"></canvas>
      <div class="centerTip" id="centerTip">クリックでポインタロック / WASDで移動</div>
      <div class="hud">
        <div class="key">W</div><div class="key">A</div><div class="key">S</div><div class="key">D</div>
        <div class="key">Shift</div><div class="key">Mouse</div>
      </div>
      <div class="tag">リアルタイム再構築</div>
    </main>
  </div>

  <!-- Three.js CDN -->
  <script src="https://unpkg.com/three@0.160.0/build/three.min.js"></script>

  <script>
  ;(() => {
    // Utility: DOM refs
    const el = {
      canvas: document.getElementById('viewport'),
      drop: document.getElementById('drop'),
      file: document.getElementById('file'),
      status: document.getElementById('status'),
      bar: document.getElementById('bar'),
      kind: document.getElementById('kind'),
      res: document.getElementById('res'),
      vp: document.getElementById('vp'),
      err: document.getElementById('err'),
      demoBtn: document.getElementById('demoBtn'),
      centerTip: document.getElementById('centerTip'),
      autoVP: document.getElementById('autoVP'),
      depthFromLuma: document.getElementById('depthFromLuma'),
      depthScale: document.getElementById('depthScale'),
      exposure: document.getElementById('exposure'),
      projFov: document.getElementById('projFov'),
      reproject: document.getElementById('reproject'),
      resetScene: document.getElementById('resetScene'),
      speed: document.getElementById('speed'),
      sens: document.getElementById('sens'),
      speedVal: document.getElementById('speedVal'),
      sensVal: document.getElementById('sensVal')
    }

    // Scene setup
    const scene = new THREE.Scene()
    scene.background = new THREE.Color(0x0b0f14)

    const renderer = new THREE.WebGLRenderer({ canvas: el.canvas, antialias: true })
    renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2))
    renderer.setSize(window.innerWidth - 380, window.innerHeight)

    const camera = new THREE.PerspectiveCamera(75, (window.innerWidth - 380)/window.innerHeight, 0.01, 500)
    camera.position.set(0, 1.6, 0.6)

    const hemi = new THREE.HemisphereLight(0xcfeaff, 0x223344, 0.6)
    scene.add(hemi)
    const dir = new THREE.DirectionalLight(0xffffff, 0.25)
    dir.position.set(3,5,2)
    scene.add(dir)

    // Floor grid
    const grid = new THREE.GridHelper(50, 50, 0x274055, 0x1c2a3f)
    grid.position.y = 0
    scene.add(grid)

    // Room
    const room = new THREE.Group()
    scene.add(room)

    const ROOM_SIZE = { w: 6, h: 3, d: 6 }
    function buildRoom() {
      room.clear()
      const mat = new THREE.MeshStandardMaterial({
        color: 0x0e1622, roughness: 0.9, metalness: 0.0
      })
      const planes = []
      // floor
      planes.push({ pos:[0,0,0], rot:[-Math.PI/2,0,0], size:[ROOM_SIZE.w, ROOM_SIZE.d] })
      // ceiling
      planes.push({ pos:[0,ROOM_SIZE.h,0], rot:[Math.PI/2,0,0], size:[ROOM_SIZE.w, ROOM_SIZE.d] })
      // back wall (forward)
      planes.push({ pos:[0,ROOM_SIZE.h/2,-ROOM_SIZE.d/2], rot:[0,0,0], size:[ROOM_SIZE.w, ROOM_SIZE.h] })
      // front wall (behind)
      planes.push({ pos:[0,ROOM_SIZE.h/2,ROOM_SIZE.d/2], rot:[0,Math.PI,0], size:[ROOM_SIZE.w, ROOM_SIZE.h] })
      // left wall
      planes.push({ pos:[-ROOM_SIZE.w/2,ROOM_SIZE.h/2,0], rot:[0,Math.PI/2,0], size:[ROOM_SIZE.d, ROOM_SIZE.h] })
      // right wall
      planes.push({ pos:[ROOM_SIZE.w/2,ROOM_SIZE.h/2,0], rot:[0,-Math.PI/2,0], size:[ROOM_SIZE.d, ROOM_SIZE.h] })

      for (const p of planes) {
        const geo = new THREE.PlaneGeometry(p.size[0], p.size[1], 1, 1)
        const mesh = new THREE.Mesh(geo, mat.clone())
        mesh.position.set(...p.pos)
        mesh.rotation.set(...p.rot)
        mesh.receiveShadow = true
        room.add(mesh)
      }
    }
    buildRoom()

    // Controls: simple FPS
    const keys = { w:false, a:false, s:false, d:false, shift:false }
    let yaw = 0, pitch = 0
    let speed = parseFloat(el.speed.value)
    let sens = parseFloat(el.sens.value)
    el.speedVal.textContent = speed.toFixed(1) + ' m/s'
    el.sensVal.textContent = sens.toFixed(3)

    function clamp(v,min,max){ return Math.max(min, Math.min(max, v)) }

    function onMouseMove(e) {
      if (!document.pointerLockElement) return
      yaw -= e.movementX * sens
      pitch -= e.movementY * sens
      pitch = clamp(pitch, -Math.PI/2 + 0.05, Math.PI/2 - 0.05)
      const q = new THREE.Quaternion()
      q.setFromEuler(new THREE.Euler(pitch, yaw, 0, 'YXZ'))
      camera.quaternion.copy(q)
    }
    function onKey(e, down) {
      const m = e.key.toLowerCase()
      if (m === 'w') keys.w = down
      else if (m === 'a') keys.a = down
      else if (m === 's') keys.s = down
      else if (m === 'd') keys.d = down
      else if (m === 'shift') keys.shift = down
    }
    function move(dt) {
      const v = new THREE.Vector3()
      const fwd = new THREE.Vector3()
      camera.getWorldDirection(fwd)
      fwd.y = 0; fwd.normalize()
      const right = new THREE.Vector3().crossVectors(fwd, new THREE.Vector3(0,1,0)).normalize()
      const run = keys.shift ? 1.7 : 1.0
      if (keys.w) v.add(fwd)
      if (keys.s) v.addScaledVector(fwd, -1)
      if (keys.a) v.addScaledVector(right, -1)
      if (keys.d) v.add(right)
      if (v.lengthSq() > 0) {
        v.normalize()
        camera.position.addScaledVector(v, speed * run * dt)
        // Keep within room bounds
        camera.position.x = clamp(camera.position.x, -ROOM_SIZE.w/2 + 0.2, ROOM_SIZE.w/2 - 0.2)
        camera.position.z = clamp(camera.position.z, -ROOM_SIZE.d/2 + 0.2, ROOM_SIZE.d/2 - 0.2)
        camera.position.y = clamp(camera.position.y, 0.9, ROOM_SIZE.h - 0.2)
      }
    }
    el.canvas.addEventListener('click', () => {
      el.canvas.requestPointerLock()
    })
    document.addEventListener('pointerlockchange', () => {
      el.centerTip.classList.toggle('show', !document.pointerLockElement)
    })
    document.addEventListener('mousemove', onMouseMove)
    document.addEventListener('keydown', e => onKey(e, true))
    document.addEventListener('keyup', e => onKey(e, false))
    el.speed.addEventListener('input', () => {
      speed = parseFloat(el.speed.value)
      el.speedVal.textContent = speed.toFixed(1) + ' m/s'
    })
    el.sens.addEventListener('input', () => {
      sens = parseFloat(el.sens.value)
      el.sensVal.textContent = sens.toFixed(3)
    })

    // Resize
    function onResize() {
      const w = window.innerWidth - 380
      const h = window.innerHeight
      renderer.setSize(w, h)
      camera.aspect = w / h
      camera.updateProjectionMatrix()
    }
    window.addEventListener('resize', onResize)

    // Image processing: Sobel + Hough to find dominant vanishing point
    const procCanvas = document.createElement('canvas')
    const procCtx = procCanvas.getContext('2d', { willReadFrequently: true })

    function toGray(data) {
      const out = new Uint8ClampedArray(data.length/4)
      for (let i=0, j=0; i<data.length; i+=4, j++) {
        const r=data[i], g=data[i+1], b=data[i+2]
        out[j] = (r*0.299 + g*0.587 + b*0.114)|0
      }
      return out
    }

    function sobel(gray, w, h) {
      const gxKernel = [-1,0,1, -2,0,2, -1,0,1]
      const gyKernel = [-1,-2,-1, 0,0,0, 1,2,1]
      const mag = new Float32Array(w*h)
      const ang = new Float32Array(w*h)
      for (let y=1; y<h-1; y++) {
        for (let x=1; x<w-1; x++) {
          let gx=0, gy=0
          let k=0
          for (let ky=-1; ky<=1; ky++) {
            for (let kx=-1; kx<=1; kx++) {
              const v = gray[(y+ky)*w + (x+kx)]
              gx += v * gxKernel[k]
              gy += v * gyKernel[k]
              k++
            }
          }
          const idx = y*w + x
          mag[idx] = Math.hypot(gx, gy)
          ang[idx] = Math.atan2(gy, gx)
        }
      }
      return { mag, ang }
    }

    function houghLines(mag, ang, w, h, threshold=80, rhoStep=1, thetaStep=Math.PI/180) {
      const maxRho = Math.hypot(w, h)
      const nrho = Math.ceil(maxRho / rhoStep)
      const ntheta = Math.ceil(Math.PI / thetaStep)
      const acc = new Uint32Array(nrho * ntheta)
      for (let y=0; y<h; y++) {
        for (let x=0; x<w; x++) {
          const idx = y*w + x
          const m = mag[idx]
          if (m < threshold) continue
          for (let t=0; t<ntheta; t++) {
            const theta = t * thetaStep
            const rho = x*Math.cos(theta) + y*Math.sin(theta)
            const r = Math.floor(rho / rhoStep)
            const aidx = r*ntheta + t
            acc[aidx]++
          }
        }
      }
      // pick top K lines
      const K = 16
      const lines = []
      for (let i=0; i<acc.length; i++) {
        if (acc[i] > threshold) {
          const r = Math.floor(i/ntheta)
          const t = i % ntheta
          lines.push({ rho: r*rhoStep, theta: t*thetaStep, votes: acc[i] })
        }
      }
      lines.sort((a,b)=>b.votes - a.votes)
      return lines.slice(0, K)
    }

    function intersectLines(lineA, lineB) {
      // line in normal form: x*cosθ + y*sinθ = ρ
      const { rho: r1, theta: t1 } = lineA
      const { rho: r2, theta: t2 } = lineB
      // convert to Cartesian: a1 x + b1 y = r1; a2 x + b2 y = r2
      const a1 = Math.cos(t1), b1 = Math.sin(t1)
      const a2 = Math.cos(t2), b2 = Math.sin(t2)
      const det = a1*b2 - a2*b1
      if (Math.abs(det) < 1e-6) return null
      const x = (r1*b2 - r2*b1) / det
      const y = (a1*r2 - a2*r1) / det
      return { x, y }
    }

    function estimateVanishingPoint(lines, w, h) {
      const pts = []
      for (let i=0; i<lines.length; i++) {
        for (let j=i+1; j<lines.length; j++) {
          const p = intersectLines(lines[i], lines[j])
          if (!p) continue
          // keep intersections roughly inside/near image bounds
          if (isFinite(p.x) && isFinite(p.y) && Math.abs(p.x) <= w*2 && Math.abs(p.y) <= h*2) {
            pts.push(p)
          }
        }
      }
      if (pts.length === 0) return { x: w/2, y: h/2, count: 0 }

      // cluster with simple mean-shift-ish averaging
      let cx = 0, cy = 0
      for (const p of pts) { cx += p.x; cy += p.y }
      cx /= pts.length; cy /= pts.length
      // refine by removing outliers
      const dists = pts.map(p => Math.hypot(p.x - cx, p.y - cy))
      const median = dists.slice().sort((a,b)=>a-b)[Math.floor(dists.length/2)]
      const keep = pts.filter((p,i)=>dists[i] <= median*1.5)
      if (keep.length > 0) {
        cx = 0; cy = 0
        for (const p of keep) { cx += p.x; cy += p.y }
        cx /= keep.length; cy /= keep.length
        return { x: cx, y: cy, count: keep.length }
      }
      return { x: cx, y: cy, count: pts.length }
    }

    // Projective texturing shader (project uploaded image as a projector onto room)
    let projectorCam = new THREE.PerspectiveCamera(60, 1, 0.01, 50)
    projectorCam.position.set(0, 1.6, ROOM_SIZE.d/2 - 0.01)
    projectorCam.lookAt(0,1.4,-ROOM_SIZE.d/2)

    const projUniforms = {
      map: { value: null },
      exposure: { value: 1.0 },
      projectorMatrix: { value: new THREE.Matrix4() },
      depthScale: { value: 0.6 },
      depthFromLuma: { value: 1.0 }
    }

    const projVertex = `
      varying vec3 vWorldPos;
      void main(){
        vec4 wp = modelMatrix * vec4(position, 1.0);
        vWorldPos = wp.xyz;
        gl_Position = projectionMatrix * viewMatrix * wp;
      }
    `
    const projFragment = `
      precision highp float;
      uniform sampler2D map;
      uniform float exposure;
      uniform float depthScale;
      uniform float depthFromLuma;
      uniform mat4 projectorMatrix;
      varying vec3 vWorldPos;

      // projective UV from projectorMatrix
      vec2 projUV(vec3 worldPos){
        vec4 p = projectorMatrix * vec4(worldPos, 1.0);
        p.xyz /= p.w;
        return p.xy * 0.5 + 0.5;
      }
      void main(){
        vec2 uv = projUV(vWorldPos);

        // clamp to avoid sampling outside
        if (uv.x < 0.0 || uv.x > 1.0 || uv.y < 0.0 || uv.y > 1.0) {
          // ambient fallback
          gl_FragColor = vec4(vec3(0.08), 1.0);
          return;
        }
        vec4 tex = texture2D(map, vec2(uv.x, 1.0 - uv.y)); // flip Y for canvas origin
        // simple depth-from-luma parallax darkening (no actual displacement in fragment; visual cue)
        float luma = dot(tex.rgb, vec3(0.299, 0.587, 0.114));
        float depthShade = mix(1.0, 0.5 + 0.5*luma, depthFromLuma);
        vec3 color = tex.rgb * exposure * depthShade;
        gl_FragColor = vec4(color, 1.0);
      }
    `
    const projMat = new THREE.ShaderMaterial({
      uniforms: projUniforms,
      vertexShader: projVertex,
      fragmentShader: projFragment,
      side: THREE.DoubleSide
    })

    function applyProjectiveMaterial() {
      for (const mesh of room.children) {
        mesh.material = projMat
      }
    }
    applyProjectiveMaterial()

    function updateProjectorMatrix() {
      projectorCam.fov = parseFloat(el.projFov.value)
      projectorCam.updateProjectionMatrix()
      projectorCam.aspect = 1.0
      projectorCam.updateMatrixWorld(true)
      const m = new THREE.Matrix4()
      m.multiply(projectorCam.projectionMatrix)
      m.multiply(new THREE.Matrix4().copy(projectorCam.matrixWorldInverse))
      projUniforms.projectorMatrix.value.copy(m)
    }
    updateProjectorMatrix()

    // Status helpers
    function setStatus(text, cls) {
      el.status.textContent = text
      el.status.classList.remove('ok', 'warn', 'err')
      if (cls) el.status.classList.add(cls)
    }
    function setProgress(p) {
      el.bar.style.width = Math.round(p*100) + '%'
    }

    // File handling
    let currentTexture = null
    let imgInfo = { w: 0, h: 0, vp: { x: null, y: null, count: 0 }, err: null, kind: '—' }

    function setInfo(kind, w, h, vp, err) {
      imgInfo = { kind, w, h, vp, err }
      el.kind.textContent = kind
      el.res.textContent = w && h ? `${w} × ${h}` : '—'
      el.vp.textContent = (vp && vp.x!=null) ? `${vp.x|0}, ${vp.y|0} (${vp.count})` : '—'
      el.err.textContent = (err!=null) ? err.toFixed(3) : '—'
    }

    function processImageBitmap(bitmap) {
      const w = bitmap.width, h = bitmap.height
      procCanvas.width = w; procCanvas.height = h
      procCtx.clearRect(0,0,w,h)
      procCtx.drawImage(bitmap, 0,0)
      const imgd = procCtx.getImageData(0,0,w,h)
      const gray = toGray(imgd.data)
      setProgress(0.15)
      const { mag, ang } = sobel(gray, w, h)
      setProgress(0.35)
      // normalize mag for threshold
      let maxMag = 0
      for (let i=0;i<mag.length;i++){ if(mag[i]>maxMag) maxMag = mag[i] }
      const thr = Math.max(50, maxMag*0.25)
      const lines = houghLines(mag, ang, w, h, thr)
      setProgress(0.6)
      const vp = el.autoVP.checked ? estimateVanishingPoint(lines, w, h) : { x: w/2, y: h/2, count: 0 }
      // simple reprojection error: average distance of intersections to vp
      let err = 0
      let count = 0
      for (let i=0;i<lines.length;i++){
        for (let j=i+1;j<lines.length;j++){
          const p = intersectLines(lines[i], lines[j])
          if (!p) continue
          err += Math.hypot(p.x - vp.x, p.y - vp.y)
          count++
        }
      }
      err = count ? err / count / Math.hypot(w,h) : 0.0

      // Orient projector to aim through vp roughly to back wall center:
      // map image vp to a direction in room space: assume projector at front wall center
      const nx = (vp.x / w) * 2 - 1
      const ny = (vp.y / h) * 2 - 1
      const aim = new THREE.Vector3(nx, -ny, -1).normalize()
      projectorCam.position.set(0, 1.5, ROOM_SIZE.d/2 - 0.001)
      const target = new THREE.Vector3(0,1.5,0).addScaledVector(aim, ROOM_SIZE.d/2)
      projectorCam.lookAt(target)
      updateProjectorMatrix()

      setProgress(0.75)
      setInfo('画像', w, h, vp, err)
      setStatus('消失点推定・射影設定完了', 'ok')
      setProgress(1.0)
    }

    function createTextureFromCanvas(canvas) {
      const tex = new THREE.CanvasTexture(canvas)
      tex.colorSpace = THREE.SRGBColorSpace
      tex.minFilter = THREE.LinearMipMapLinearFilter
      tex.magFilter = THREE.LinearFilter
      tex.wrapS = THREE.ClampToEdgeWrapping
      tex.wrapT = THREE.ClampToEdgeWrapping
      return tex
    }

    async function handleImageFile(file) {
      setStatus('画像を読み込み中…', '')
      setProgress(0.05)
      const blobURL = URL.createObjectURL(file)
      const img = await createImageBitmap(await (await fetch(blobURL)).blob())
      URL.revokeObjectURL(blobURL)

      const canvas = document.createElement('canvas')
      const maxDim = 2048
      const scale = Math.min(1, maxDim / Math.max(img.width, img.height))
      canvas.width = Math.round(img.width * scale)
      canvas.height = Math.round(img.height * scale)
      const ctx = canvas.getContext('2d')
      ctx.drawImage(img, 0, 0, canvas.width, canvas.height)

      currentTexture = createTextureFromCanvas(canvas)
      projUniforms.map.value = currentTexture
      projUniforms.exposure.value = parseFloat(el.exposure.value)
      projUniforms.depthScale.value = parseFloat(el.depthScale.value)
      projUniforms.depthFromLuma.value = el.depthFromLuma.checked ? 1.0 : 0.0

      processImageBitmap(img)
    }

    async function handleVideoFile(file) {
      setStatus('動画の先頭フレームを抽出中…', '')
      setProgress(0.05)
      const blobURL = URL.createObjectURL(file)
      const video = document.createElement('video')
      video.src = blobURL
      video.muted = true
      video.playsInline = true
      await video.play().catch(()=>{})
      await new Promise(resolve => {
        if (video.readyState >= 2) resolve()
        else video.addEventListener('loadeddata', resolve, { once: true })
      })
      video.pause()

      const canvas = document.createElement('canvas')
      const maxDim = 1920
      const scale = Math.min(1, maxDim / Math.max(video.videoWidth, video.videoHeight))
      canvas.width = Math.round(video.videoWidth * scale)
      canvas.height = Math.round(video.videoHeight * scale)
      const ctx = canvas.getContext('2d')
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height)
      URL.revokeObjectURL(blobURL)

      currentTexture = createTextureFromCanvas(canvas)
      projUniforms.map.value = currentTexture
      projUniforms.exposure.value = parseFloat(el.exposure.value)
      projUniforms.depthScale.value = parseFloat(el.depthScale.value)
      projUniforms.depthFromLuma.value = el.depthFromLuma.checked ? 1.0 : 0.0

      const bmp = await createImageBitmap(canvas)
      processImageBitmap(bmp)
      setInfo('動画（先頭フレーム）', canvas.width, canvas.height, imgInfo.vp, imgInfo.err)
    }

    // Drag & drop
    function prevent(e){ e.preventDefault(); e.stopPropagation() }
    ;['dragenter','dragover','dragleave','drop'].forEach(type => {
      el.drop.addEventListener(type, prevent)
    })
    el.drop.addEventListener('dragenter', ()=> el.drop.classList.add('drag'))
    el.drop.addEventListener('dragover', ()=> el.drop.classList.add('drag'))
    el.drop.addEventListener('dragleave', ()=> el.drop.classList.remove('drag'))
    el.drop.addEventListener('drop', (e) => {
      el.drop.classList.remove('drag')
      const file = e.dataTransfer.files?.[0]
      if (!file) return
      if (file.type.startsWith('image/')) handleImageFile(file)
      else if (file.type.startsWith('video/')) handleVideoFile(file)
      else setStatus('未対応のファイル形式です', 'err')
    })
    el.file.addEventListener('change', () => {
      const file = el.file.files?.[0]
      if (!file) return
      if (file.type.startsWith('image/')) handleImageFile(file)
      else if (file.type.startsWith('video/')) handleVideoFile(file)
      else setStatus('未対応のファイル形式です', 'err')
    })

    // Demo image (royalty-free placeholder via data URL)
    el.demoBtn.addEventListener('click', async () => {
      setStatus('デモ画像を読み込み中…', '')
      setProgress(0.05)
      // A small embedded data URL of a corridor-like image substitute
      const demo = new Image()
      demo.crossOrigin = 'anonymous'
      // Minimalistic gradient that simulates perspective (no external network dependency)
      const canvas = document.createElement('canvas')
      canvas.width = 1280; canvas.height = 720
      const ctx = canvas.getContext('2d')
      const g = ctx.createLinearGradient(0, 0, 0, canvas.height)
      g.addColorStop(0, '#1a2433')
      g.addColorStop(1, '#0e1622')
      ctx.fillStyle = g
      ctx.fillRect(0, 0, canvas.width, canvas.height)
      // draw some lines to mimic corridor
      ctx.strokeStyle = '#9fb6d4'
      ctx.lineWidth = 2
      for(let i=0;i<8;i++){
        ctx.beginPath()
        ctx.moveTo(100 + i*140, 30)
        ctx.lineTo(canvas.width/2, canvas.height - 30)
        ctx.stroke()
      }
      currentTexture = createTextureFromCanvas(canvas)
      projUniforms.map.value = currentTexture
      projUniforms.exposure.value = parseFloat(el.exposure.value)
      projUniforms.depthScale.value = parseFloat(el.depthScale.value)
      projUniforms.depthFromLuma.value = el.depthFromLuma.checked ? 1.0 : 0.0

      const bmp = await createImageBitmap(canvas)
      processImageBitmap(bmp)
      setInfo('デモ画像', canvas.width, canvas.height, imgInfo.vp, imgInfo.err)
    })

    // Reproject / Reset
    el.reproject.addEventListener('click', () => {
      if (!currentTexture) { setStatus('画像/動画を先に読み込んでください', 'warn'); return }
      projUniforms.exposure.value = parseFloat(el.exposure.value)
      projUniforms.depthScale.value = parseFloat(el.depthScale.value)
      projUniforms.depthFromLuma.value = el.depthFromLuma.checked ? 1.0 : 0.0
      updateProjectorMatrix()
      setStatus('再投影しました', 'ok')
    })
    el.resetScene.addEventListener('click', () => {
      buildRoom()
      applyProjectiveMaterial()
      camera.position.set(0, 1.6, 0.6)
      yaw = 0; pitch = 0
      projectorCam.position.set(0, 1.6, ROOM_SIZE.d/2 - 0.01)
      projectorCam.lookAt(0,1.4,-ROOM_SIZE.d/2)
      updateProjectorMatrix()
      setStatus('シーンを初期化しました', 'ok')
    })

    // Render loop
    let last = performance.now()
    function tick(now) {
      const dt = Math.min(0.05, (now - last) / 1000)
      last = now
      move(dt)
      renderer.render(scene, camera)
      requestAnimationFrame(tick)
    }
    requestAnimationFrame(tick)

    // Initial tip
    setTimeout(()=> el.centerTip.classList.add('show'), 300)

    // Safe guards
    window.addEventListener('error', (e) => {
      setStatus('エラーが発生しました: ' + e.message, 'err')
    })
  })()
  </script>
</body>
</html>
